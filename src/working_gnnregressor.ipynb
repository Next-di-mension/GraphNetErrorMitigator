{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8556]])\n",
      "time taken 265.3860263824463\n",
      "Iteration 1\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8621]])\n",
      "time taken 257.6061635017395\n",
      "Iteration 2\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8660]])\n",
      "time taken 260.7168884277344\n",
      "Iteration 3\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8704]])\n",
      "time taken 262.17924880981445\n",
      "Iteration 4\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8718]])\n",
      "time taken 263.61512565612793\n",
      "Iteration 5\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8727]])\n",
      "time taken 263.54640460014343\n",
      "Iteration 6\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8732]])\n",
      "time taken 262.42164182662964\n",
      "Iteration 7\n",
      "tensor([[0, 5, 1, 4, 0, 4, 1, 5],\n",
      "        [2, 7, 3, 6, 3, 7, 2, 6]])\n",
      "tensor([3., 3., 3., 3., 2., 2., 2., 2.])\n",
      "Output of the GNN for a test graph: tensor([[-1.8705]])\n",
      "time taken 264.93785214424133\n",
      "Iteration 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 181\u001b[0m\n\u001b[0;32m    178\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(output, target) \u001b[38;5;66;03m#+ l1_lambda * l1_norm\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 181\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(train_loader)}')\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Srushti\\OneDrive\\Documents\\New folder\\codes\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Srushti\\OneDrive\\Documents\\New folder\\codes\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Srushti\\OneDrive\\Documents\\New folder\\codes\\.venv\\lib\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Srushti\\OneDrive\\Documents\\New folder\\codes\\.venv\\lib\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Srushti\\OneDrive\\Documents\\New folder\\codes\\.venv\\lib\\site-packages\\torch\\optim\\adam.py:385\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    384\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 385\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    388\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch_geometric import loader\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    if use_cuda: \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel(r'data\\2times\\neural_mitigation_data_wo_s_new_ansatz.xlsx')\n",
    "\n",
    "\n",
    "def ParseOp(string):\n",
    "    string_list = list(string.strip('()').split(\"), (\"))\n",
    "    # how to remove the extra brackets\n",
    "    string_list = list(map(lambda x: x.strip('('), string_list))\n",
    "    string_list = list(map(lambda x: x.strip(')'), string_list))\n",
    "    string_list = [tuple(map(int, sub.split(', '))) for sub in string_list]\n",
    "    return string_list\n",
    "\n",
    "# Prepare the graph data\n",
    "num_nodes = 8\n",
    "num_features = 4\n",
    "num_output = 1\n",
    "batch_size = 1\n",
    "\n",
    "def Create_graph_data(index, op_col):\n",
    "        edges = []\n",
    "        x = torch.eye(num_nodes)\n",
    "        op = ParseOp(op_col[index])\n",
    "        for i in range(0, len(op)-1, 2):\n",
    "            edges.append((op[i][0], op[i+1][0]))\n",
    "            edges.append((op[i][1], op[i+1][1]))\n",
    "                \n",
    "        # Normalize edges to have smaller index first\n",
    "        normalized_edges = [tuple(sorted(edge)) for edge in edges]\n",
    "\n",
    "        # Count occurrences of each edge\n",
    "        edge_counts = Counter(normalized_edges)\n",
    "\n",
    "        # Prepare edge_index and edge_weight\n",
    "        unique_edges = list(edge_counts.keys())\n",
    "        edge_index = torch.tensor(unique_edges, dtype=torch.long).t().contiguous()\n",
    "        edge_weight = torch.tensor([edge_counts[edge] for edge in unique_edges], dtype=torch.float)\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "inputs = df[['Noisy_val_approx', 'sum_cx', 'sum_cx0', 'sum_t2']]\n",
    "inputs = torch.tensor(inputs.values).reshape(-1, num_features)\n",
    "inputs = inputs.type(torch.float32)\n",
    "targets = df['Ideal_val']\n",
    "targets = torch.tensor(targets.values).reshape(-1, num_output)\n",
    "targets = targets.type(torch.float32)\n",
    "Operator_col = df['Operator']\n",
    "\n",
    "# Create dataloader\n",
    "dataset = [(Create_graph_data(i, Operator_col), inputs[i], targets[i]) for i in range(len(Operator_col))]\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_loader = loader.DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = loader.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# data_loader = loader.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# random_seed(42, False)\n",
    "IS_CUDA = torch.cuda.is_available()\n",
    "DEVICE = 'cuda:0' if IS_CUDA else 'cpu'\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(8, 64)\n",
    "        self.conv2 = GCNConv(64, 1) \n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        # x = F.dropout(x, p=0.01)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return x\n",
    "\n",
    "class FCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features , 64)  \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, num_features)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, p=0.02)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.dropout(x, p=0.02)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.gnn = GNN()\n",
    "        # self.regressor = FCNN()\n",
    "        self.fc1 = nn.Linear(num_nodes + num_features, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight, noisy_value):\n",
    "        graph_out = self.gnn(x, edge_index, edge_weight)\n",
    "        graph_out = graph_out.reshape(1, -1)\n",
    "        \n",
    "        # reg_out = self.regressor(noisy_value)\n",
    "        # reg_out = torch.tensor(reg_out.detach().numpy()[0])\n",
    "        \n",
    "\n",
    "        noisy_input = noisy_value\n",
    "        noisy_input = torch.tensor(noisy_input.detach().numpy()[0])\n",
    "        combined = torch.cat((graph_out, noisy_input.unsqueeze(0)), dim=1)\n",
    "        combined = self.fc1(combined)\n",
    "        combined = F.relu(combined)\n",
    "        # combined = F.dropout(combined, p=0.02)\n",
    "        combined = self.fc2(combined)\n",
    "        combined = F.relu(combined)\n",
    "        # combined = F.dropout(combined, p=0.02)\n",
    "        combined = self.fc3(combined)\n",
    "        return combined\n",
    "\n",
    "# Initialize the model\n",
    "model = CombinedModel()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 30 # How many epochs to wait after last time validation loss improved\n",
    "best_loss = float('inf')\n",
    "epochs_since_improvement = 0\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for i in range(10):\n",
    "    time0 = time()\n",
    "    print('Iteration', i)\n",
    "    for epoch in range(100):\n",
    "        model = model.to(DEVICE)\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            target = torch.tensor(batch[2].detach().numpy()[0])\n",
    "            target = target.reshape(1, -1)\n",
    "            \n",
    "            output = model(batch[0].x, batch[0].edge_index, batch[0].edge_attr, batch[1]) \n",
    "            # l1_lambda = 0.001  # The regularization parameter\n",
    "            # l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = F.mse_loss(output, target) #+ l1_lambda * l1_norm\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        # print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "            \n",
    "                target = torch.tensor(batch[2].detach().numpy()[0])\n",
    "                target = target.reshape(1, -1)\n",
    "                \n",
    "                output = model(batch[0].x, batch[0].edge_index, batch[0].edge_attr, batch[1]) \n",
    "                # print('predicted_value', output, 'true_value', target)\n",
    "                # l1_lambda = 0.0001  # The regularization parameter\n",
    "                # l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "                loss = F.mse_loss(output, target) #+ l1_lambda * l1_norm\n",
    "        \n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_loss /= len(val_loader)\n",
    "            # print(f'Epoch {epoch+1}, Validation Loss: {val_loss}')\n",
    "\n",
    "        # Check for improvement\n",
    "        # make directory\n",
    "        \n",
    "        # model_path = r'models\\2times\\early_stopping\\best_model_2times.pt'\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            epochs_since_improvement = 0\n",
    "            # Save the model if you want\n",
    "            # torch.save(model.state_dict(), model_path)\n",
    "        else:\n",
    "            epochs_since_improvement += 1\n",
    "\n",
    "    # if epochs_since_improvement >= patience:\n",
    "    #     print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "    #     break\n",
    "\n",
    "    # Test the model on final ansatz\n",
    "    model.eval()\n",
    "    op_string = '(((0, 5), (2, 7)), ((1, 4), (3, 6)), ((0, 4), (2, 6)), ((1, 5), (3, 7)), ((0, 4), (3, 7)), ((1, 4), (2, 7)), ((4, 5), (6, 7)), ((0, 1), (2, 3)), ((1, 5), (2, 6)), ((0, 5), (3, 6)))'\n",
    "    # op_string = '(((0, 5), (2, 7)), ((1, 4), (3, 6)), ((1, 5), (3, 7)), ((0, 4), (2, 6)), ((1, 4), (2, 7)), ((0, 4), (3, 7)), ((0, 1), (2, 3)), ((4, 5), (6, 7)), ((1, 5), (2, 6)), ((0, 5), (3, 6)))'\n",
    "\n",
    "    df_test = pd.DataFrame({\n",
    "        'Operator': op_string,\n",
    "        'Input': [-1.86]\n",
    "    })\n",
    "\n",
    "\n",
    "    op_col = df_test['Operator']\n",
    "    noisy_val = torch.tensor([[-1.308892923286312, 80/224,  60/224, 1]])\n",
    "    test_graph = Create_graph_data(0, op_col)\n",
    "    print(test_graph.edge_index)\n",
    "    print(test_graph.edge_attr)\n",
    "    # print('loss', loss_list) \n",
    "\n",
    "    # m = CombinedModel()\n",
    "    # m = m.to(DEVICE)\n",
    "    # m.eval()\n",
    "    # m.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        graph_output = model(test_graph.x, test_graph.edge_index, test_graph.edge_attr, noisy_val)\n",
    "        print(\"Output of the GNN for a test graph:\", graph_output)\n",
    "    print('time taken', time() - time0)\n",
    "\n",
    "# save model \n",
    "# g = graph_output.detach().numpy()\n",
    "# g  = str(g)\n",
    "# # remove element from string\n",
    "# g = g.strip('[')\n",
    "# g = g.strip(']')\n",
    "# # remove element from string\n",
    "# g = g.replace('-', '')\n",
    "# g = g.replace('.', '')\n",
    "\n",
    "# model_path = r'models\\2times\\model_2times_approx_noisy_wo_s_new_ansatz_' + g + '.pt'\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# load model\n",
    "# m = CombinedModel()\n",
    "# m = m.to(DEVICE)\n",
    "# m.eval()\n",
    "# m.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     graph_output = m(test_graph.x, test_graph.edge_index, test_graph.edge_attr, noisy_val)\n",
    "#     print(\"Output of the GNN for a test graph:\", graph_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for sublist in e for item in sublist]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
